# CASA-Calib (Paper with Code)
CASA-Calib: A Context-Aware Semantic Alignment Method for LiDAR-Camera Extrinsic Calibration for Vehicle Perception Systems

> **Note:** This repository is currently being actively updated.  
> Components related to dataset construction, visualization tooling, and CASA-Calib modules  
> are under continuous refinement. Additional documentation and examples will be released soon.


Author: Yuan-Ting Fu

This repository provides the official MATLAB implementation of the core components used in the CASA-Calib paper, including:

CASA-Loss (full loss formulation used during calibration)

Cost landscape visualization (Fig. 7)

Tau sensitivity analysis (Fig. 4)

Perturbation robustness experiments (Fig. 5)

All scripts are self-contained and assume you have already prepared the curated Waymo dataset described in the paper.

```text
CASA_Calib/
â”‚
â”œâ”€â”€ CASA_Loss.m                    # Core CASA-Loss (Section III of paper)
â”‚
â”œâ”€â”€ cost_landscape.m               # J(Î”ty, Î”tz) landscape â†’ Fig. 7
â”‚
â”œâ”€â”€ Tau_Sensitivity_Analysis.m     # Tau sweep & stability band â†’ Fig. 4
â”‚
â”œâ”€â”€ perturbation_analysis.m        # Perturbation robustness â†’ Fig. 5
â”‚
â”œâ”€â”€ img_contour_seq_fast.m         # Contour sequencing (used by CASA-Loss)
â”œâ”€â”€ LiDAR_contour_extraction_opt.m # LiDAR contour extraction
â”œâ”€â”€ loss_proj.m                    # Local SDS similarity (1D/2D)
â”œâ”€â”€ loss_shape_optimized.m         # IoU, centroid consistency (global terms)
â”‚
â””â”€â”€ README.md                      # This file
```

ğŸ¯ How to Reproduce Figures in the Paper
1. Figure 4 â€” Tau Sensitivit
Run:
Tau_Sensitivity_Analysis

Outputs:
Tau sweep (% improvement)
Pareto plot
Distance-to-ideal score + 2% stability band
Matches Fig. 4(a) and Fig. 4(b).

2. Figure 5 â€” Perturbation Robustness

Run:
perturbation_analysis

Choose:
Rotation-only
Translation-only
Rotation + translation (default)

Outputs:
average rotation error vs perturbation
average translation error vs perturbation
optional: loss / keep-ratio visualization
Reproduces Fig. 5(a)(b).

3. Figure 7 â€” Cost Landscape (2D + 3D)
Run:
cost_landscape

The script computes the multi-frame CASA cost around ground-truth:
3D surface of J(Î”ty, Î”tz)
2D contour + metrics (d*, FWHM, AÎµ)
Reproduces Fig. 7.

4. CASA-Loss (Core Loss Function)

CASA_Loss.m implements the exact formulation in Section III:

| Term                          | Description                             |
| ----------------------------- | --------------------------------------- |
| **IoU similarity**            | Global shape alignment                  |
| **Centroid consistency (CC)** | Penalizes shifts between contours       |
| **SDS-1D**                    | Line-like local distribution similarity |
| **SDS-2D**                    | Area-like local distribution similarity |
| **Î± coupling**                | IoU-guided weighting                    |

This function is used by all optimization scripts.

ğŸ”— Function Dependency Graph
```text
CASA_Loss
 â”œâ”€â”€ img_contour_seq_fast
 â”œâ”€â”€ LiDAR_contour_extraction_opt
 â”œâ”€â”€ loss_proj
 â””â”€â”€ loss_shape_optimized

perturbation_analysis
 â””â”€â”€ CASA_Loss

cost_landscape
 â””â”€â”€ CASA_Loss
```

Semanticâ€“Geometric Dataset Builder

Contribution III â€” Semanticâ€“Geometric Test Set Construction

This repository includes a custom data extraction tool that constructs a curated semanticâ€“geometric test set derived from the Waymo Open Dataset, as described in Contribution 3 of our paper:


â€œWe construct and release a curated semanticâ€“geometric test set based on the Waymo Open Dataset, providing reliable instance-level correspondences for accurate evaluation and benchmarking of semantic-assisted LiDARâ€“camera calibration methods.â€


Unlike standard datasetsâ€”where


LiDAR instance IDs and image instance IDs do not correspond,


cameraâ€“LiDAR associations must be manually aligned, and


segmentation labels may contain annotation errors,


our tool automatically aligns per-instance LiDAR and camera semantic labels, and exports a cleaned, structured dataset suitable for semantic-assisted calibration research (e.g., CASA-Calib).

ğŸ›  Semanticâ€“Geometric Dataset Builder
File: waymo_semantic_geometric_builder.py

This script processes raw .tfrecord files from the Waymo Open Dataset and generates a pairwise-consistent LiDARâ€“camera dataset with:

âœ” Reliable instance-level correspondences

âœ” Pixel-level image segmentation masks

âœ” LiDAR point-level semantic & instance labels

âœ” Synchronized calibration matrices

âœ” A directory structure compatible with CASA-Calib


ğŸ“¦ Output Directory Structure

After running the tool, each valid frame will be exported as:

```text
waymo_segment_data/
 â””â”€â”€ <sequence_id>/
      â””â”€â”€ <tfrecord_name>/
           â””â”€â”€ <frame_id>/
                â”œâ”€â”€ calib.txt                 # KITTI-style cameraâ€“LiDAR extrinsic
                â”œâ”€â”€ img_raw.png               # RGB image
                â”œâ”€â”€ panoptic_label_front.png  # image segmentation (uint16)
                â”œâ”€â”€ instance_label_front.png  # instance map (uint16)
                â”œâ”€â”€ instance_waymo.png        # original Waymo instance ID map
                â”œâ”€â”€ points_all.txt            # LiDAR XYZ points (all beams)
                â”œâ”€â”€ point_labels_all.txt      # corresponding semantic/instance IDs
                â”œâ”€â”€ lidar.bin                 # binary point cloud file (float32)
                â””â”€â”€ ... (additional metadata)
```

This format is fully compatible with CASA-Calib, and can also be used for:

1.Semantic calibration

2.Instance-matching research

3.LiDAR-camera fusion

4.3D instance segmentation training

ğŸ“¦ Description for Semanticâ€“Geometric Dataset Builder
*A core component for constructing the CASA-Calib semanticâ€“geometric evaluation dataset.*

This repository includes a dedicated extraction tool to convert raw Waymo Open Dataset
`.tfrecord` files into a curated semanticâ€“geometric dataset.  
This dataset is required for evaluating instance-level LiDARâ€“camera calibration methods
and corresponds to **Contribution 3** of the CASA-Calib paper.

### âœ¨ Purpose  
Waymo provides high-quality but **independently generated** camera and LiDAR segmentation
annotations. CASA-Calib requires a dataset in which:

- semantic labels from *both* modalities are consistently extracted  
- LiDAR segmentation is converted into per-point labels  
- camera instance masks can be paired with LiDAR object clusters  
- each frame contains complete segmentation annotations  
- manual (or automatic) LiDARâ€“image instance correspondence can be established  

This extractor performs all the above and exports a clean, structured dataset suitable
for downstream calibration evaluation.

---

## Features of the Extractor  
- Extracts RGB images, panoptic labels, semantic labels, and instance masks  
- Converts Waymoâ€™s LiDAR range-image segmentation into **3D point-level labels**  
- Saves LiDAR point clouds (`lidar.bin`), semantic labels, and projection information  
- Exports KITTI-style calibration matrices (`calib.txt`)  
- Filters invalid frames lacking segmentation labels  
- Provides a **Qt-based GUI** for interactive LiDARâ€“image instance matching  
- GUI buttons: **Save Match**, **Clear Selection**, **Skip Frame**, **Reset View**  
- Produces a CSV summary listing all matched instances per sequence  

## Matching GUI Overview

CASA-Calib includes an interactive Qt-based GUI for establishing instance-level
correspondences between camera segmentation masks and LiDAR point clusters.
This tool is essential for validating semanticâ€“geometric consistency and for
constructing high-quality benchmark data.

The interface consists of four synchronized visualizations:

1. **Image Instance Label (Top-Left)**  
   Displays the instance-level segmentation mask from the camera.  
   Each instance is assigned a unique color and labeled with its instance ID.

2. **LiDAR BEV Projection â€” Top Instances (Top-Right)**  
   Shows the most prominent LiDAR object clusters in Birdâ€™s-Eye-View (BEV).  
   Each cluster (instance ID) is color-coded consistently across subplots.

3. **All LiDAR Points Projected to the Image (Bottom-Left)**  
   Projects every LiDAR point into the camera frame, colored by depth (m).  
   This allows users to inspect geometric alignment and calibration consistency.

4. **Semantic Point Cloud Projection (Bottom-Right)**  
   Projects only semantically valid LiDAR points and colors them by instance ID.
   This view highlights object-level alignment between modalities.

### GUI Interaction

The interface supports the following actions:

| Button | Function |
|--------|----------|
| **Clear Selection** | Removes all selected pixel and LiDAR selections |
| **Save Match** | Stores the current pixel â†” LiDAR instance correspondence |
| **Skip Frame** | Discards the current frame and removes temporary output |
| **Reset View** | Resets zoom and panning for all subplots |

### Example Screenshots

Below are example GUI screenshots captured during matching:

#### Image Instance Label + LiDAR BEV Projection
   
<img width="1919" height="1027" alt="GUI_1" src="https://github.com/user-attachments/assets/a5e32c39-c8eb-489e-981e-1c725f575ad2" />


#### Pixel Selection + LiDAR Cluster Highlighting

<img width="1919" height="1029" alt="GUI_2" src="https://github.com/user-attachments/assets/d5f07935-f514-4716-a946-7eb1ccefe39b" />


#### Final Instance Projection and Correspondence Visualization

<img width="1919" height="1029" alt="GUI_3" src="https://github.com/user-attachments/assets/75ec98dc-a7a5-4c56-8a9d-e6a09e17878e" />



   

ğŸ“© Questions / Issues

If you encounter missing files, dataset format questions, or need help adapting the code, feel free to open a GitHub issue or contact the author.

